{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb3cf3e-dcdc-4e03-8669-e68cd01f2848",
   "metadata": {},
   "source": [
    "# 基礎集計\n",
    "\n",
    "1. 形態素解析  \n",
    "1. 係り受け解析  \n",
    "1. N-gram解析  \n",
    "上記を行い、カテゴリ別に出現する単語の傾向把握と、全カテゴリとのリフト値から差分を確認する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350307f6-4269-49f5-8e39-747fd50d2d55",
   "metadata": {},
   "source": [
    "# 出力ディレクトリの指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f03082f-5d4a-4e24-b479-651a993b3ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変更箇所\n",
    "input_dir = \"../data/preprocessing/\"\n",
    "output_dir = \"../data/basic_agg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca5b040-dbc8-4ef7-9e67-dc60bfd2ff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "存在するディレクトリです\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.isdir(output_dir):\n",
    "    print(\"存在するディレクトリです\")\n",
    "else:\n",
    "    os.makedirs(output_dir)\n",
    "    print(\"出力ディレクトリを作成しました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b68e1e2f-9373-4a9a-851c-3b5e351b4f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データ数:  1\n",
      "['../data/preprocessing/all_category_df.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "input_paths = glob.glob(f\"{input_dir}*.csv\")\n",
    "print(\"データ数: \", len(input_paths))\n",
    "print(input_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd389364-1449-4cf2-8a22-88b8f8265285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基礎集計に使用するDataFrameのパスを指定\n",
    "input_path = input_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d453ce8-1924-408e-ae80-49089eca1f5d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b88133bb-6464-4dfa-9c68-97dbc98c2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "\n",
    "mc = MeCab.Tagger(\"-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d16ae5a1-62b7-49d0-b5e0-79362864d865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>友人代表のスピーチ、独女はどうこなしている?\\n もうすぐジューン・ブライドと呼ばれる0月。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>ネットで断ち切れない元カレとの縁\\n 携帯電話が普及する以前、恋人への連絡ツールは一般電話が...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                               text\n",
       "0  dokujo-tsushin  友人代表のスピーチ、独女はどうこなしている?\\n もうすぐジューン・ブライドと呼ばれる0月。...\n",
       "1  dokujo-tsushin  ネットで断ち切れない元カレとの縁\\n 携帯電話が普及する以前、恋人への連絡ツールは一般電話が..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_category_df = pd.read_csv(input_path)\n",
    "all_category_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4134c8-c724-4992-a46b-31455407dcd1",
   "metadata": {},
   "source": [
    "# 形態素解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2deb9244-347a-4960-820c-d6e4079767a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun(text):\n",
    "    \"\"\" テキストから名詞を抜き出してカウンターを作成\"\"\"\n",
    "    \n",
    "    counter = {} # (名詞, 出現数)のcounter\n",
    "\n",
    "    for one_pos in mc.parse(text).split(\"\\n\"):\n",
    "        if (one_pos == \"EOS\") or (len(one_pos) == 0):\n",
    "            continue\n",
    "        surf, mc_result = one_pos.split(\"\\t\")\n",
    "        #品詞, 品詞細分類1,_,_,_,_,原型, _ \n",
    "        pos0, pos1, _, _, _, _, base, *_ = mc_result.split(\",\")\n",
    "        if (pos0 == \"名詞\") & (pos1 == \"一般\"):\n",
    "\n",
    "            if base == \"*\":\n",
    "                noun = surf\n",
    "            else:\n",
    "                noun = base\n",
    "\n",
    "            if noun in counter:\n",
    "                counter[noun] += 1\n",
    "            else:\n",
    "                counter[noun] = 1\n",
    "    \n",
    "    counter = sorted(counter.items(), \n",
    "                          key=lambda x:x[1], \n",
    "                          reverse=True)\n",
    "    return counter\n",
    "\n",
    "def extract_verb(text):\n",
    "    \"\"\" テキストから動詞を抜き出してカウンターを作成\"\"\"\n",
    "    \n",
    "    # Dockerfileで未知語の更新ができなかったため無理やり\n",
    "    # 記号系が後述の[名詞　サ変接続]に引っかかることを回避\n",
    "    mark = \"[!#$%&\\'\\\\\\\\()*+,-./:;<=>?@[\\\\]^_`\"\\\n",
    "           \"\\{|}~「」〔〕“”〈〉『』【】＆＊・（）＄＃＠。、？！｀＋￥％ 　]\"\n",
    "    stop_mark = re.compile(mark)\n",
    "    word = \"(する|いる|れる|なる|ある|できる|られる|せる|おる|てる)\"\n",
    "    stop_word = re.compile(word)\n",
    "    \n",
    "    counter = {} # (名詞, 出現数)のcounter\n",
    "    for one_pos in mc.parse(text).split(\"\\n\"):\n",
    "        if (one_pos == \"EOS\") or (len(one_pos) == 0):\n",
    "            continue\n",
    "\n",
    "        surf, mc_result = one_pos.split(\"\\t\")\n",
    "        #品詞, 品詞細分類1,_,_,_,_,原型, _ \n",
    "        pos0, pos1, _, _, _, _, base, *_ = mc_result.split(\",\")\n",
    "\n",
    "        if (stop_mark.search(surf)) or (stop_word.search(base)):\n",
    "            continue\n",
    "    \n",
    "        if pos0 == \"動詞\":\n",
    "            if base == \"*\":\n",
    "                verb = surf\n",
    "            else:\n",
    "                verb = base\n",
    "            if verb in counter:\n",
    "\n",
    "                counter[verb] += 1\n",
    "            else:\n",
    "                counter[verb] = 1\n",
    "\n",
    "        elif (pos0 == \"名詞\") & (pos1 == \"サ変接続\"):\n",
    "                \n",
    "            if base == \"*\":\n",
    "                verb = f\"{surf}する\"\n",
    "            else:\n",
    "                verb = f\"{base}する\"\n",
    "\n",
    "            if verb in counter:\n",
    "                counter[verb] += 1\n",
    "            else:\n",
    "                counter[verb] = 1\n",
    "    \n",
    "    counter = sorted(counter.items(), \n",
    "                          key=lambda x:x[1], \n",
    "                          reverse=True)\n",
    "    return counter\n",
    "\n",
    "def extract_adjective(text):\n",
    "    \"\"\" テキストから名詞を抜き出してカウンターを作成\"\"\"\n",
    "    \n",
    "    counter = {} # (名詞, 出現数)のcounter\n",
    "\n",
    "    for one_pos in mc.parse(text).split(\"\\n\"):\n",
    "        if (one_pos == \"EOS\") or (len(one_pos) == 0):\n",
    "            continue\n",
    "        surf, mc_result = one_pos.split(\"\\t\")\n",
    "        #品詞, 品詞細分類1,_,_,_,_,原型, _ \n",
    "        pos0, pos1, _, _, _, _, base, *_ = mc_result.split(\",\")\n",
    "        if ((pos0 == \"形容詞\") & (pos1 == \"自立\")) or \\\n",
    "           ((pos0 == \"名詞\") & (pos1 == \"形容動詞語幹\")):\n",
    "\n",
    "            if base == \"*\":\n",
    "                noun = surf\n",
    "            else:\n",
    "                noun = base\n",
    "\n",
    "            if noun in counter:\n",
    "                counter[noun] += 1\n",
    "            else:\n",
    "                counter[noun] = 1\n",
    "    \n",
    "    counter = sorted(counter.items(), \n",
    "                          key=lambda x:x[1], \n",
    "                          reverse=True)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94d7530f-637c-481a-8c76-5916fad672f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pos_counter_df(texts, pos=\"\"):\n",
    "    \"\"\" 品詞別のカウントDataFrame作成\n",
    "    \n",
    "        args:\n",
    "            texts(list): データフレームの1カラムをリスト化\n",
    "            pos(str): noun or verb or adjective\n",
    "    \"\"\"\n",
    "    \n",
    "    counter = {}\n",
    "    for text in tqdm(texts):\n",
    "\n",
    "        if pos == \"noun\":\n",
    "            counter_1text = extract_noun(text)\n",
    "        elif pos == \"verb\":\n",
    "            counter_1text = extract_verb(text)\n",
    "        elif pos == \"adjective\":\n",
    "            counter_1text = extract_adjective(text)\n",
    "        else:\n",
    "            print(\"posを指定してください。空DFを返します\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        for key, val in counter_1text:\n",
    "            if key in counter:\n",
    "                counter[key] += 1\n",
    "            else:\n",
    "                counter[key] = 1\n",
    "\n",
    "    counter = sorted(counter.items(), \n",
    "                          key=lambda x:x[1], \n",
    "                          reverse=True)\n",
    "\n",
    "    result = pd.DataFrame(counter, columns=[pos, \"count\"])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a191a83-cf5c-4650-a972-85da04248115",
   "metadata": {},
   "source": [
    "## 全体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b99411f-b6aa-4444-951a-fac36380ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7367/7367 [00:18<00:00, 407.72it/s]\n",
      "100%|██████████| 7367/7367 [00:18<00:00, 401.00it/s]\n",
      "100%|██████████| 7367/7367 [00:16<00:00, 448.25it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = all_category_df[\"text\"].tolist()\n",
    "\n",
    "for pos in [\"noun\", \"verb\", \"adjective\"]:\n",
    "    result = create_pos_counter_df(texts, pos=pos)\n",
    "\n",
    "    # カテゴリ別リフト値を算出するために使用\n",
    "    count_sum = result[\"count\"].sum()\n",
    "    result[\"ratio\"] = result[\"count\"].apply(lambda x: x / count_sum)\n",
    "\n",
    "    result.to_csv(f\"{output_dir}all_{pos}.csv\", \n",
    "                  encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a6449-b207-494e-adcf-d41bd84a1f1d",
   "metadata": {},
   "source": [
    "## カテゴリ別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a6db02f-8467-4c89-9a15-ada576feb747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 870/870 [00:02<00:00, 368.31it/s]\n",
      "100%|██████████| 870/870 [00:01<00:00, 439.61it/s]\n",
      "100%|██████████| 864/864 [00:01<00:00, 664.60it/s]\n",
      "100%|██████████| 511/511 [00:01<00:00, 299.60it/s]\n",
      "100%|██████████| 870/870 [00:02<00:00, 391.11it/s]\n",
      "100%|██████████| 842/842 [00:02<00:00, 389.36it/s]\n",
      "100%|██████████| 870/870 [00:02<00:00, 378.63it/s]\n",
      "100%|██████████| 900/900 [00:01<00:00, 768.57it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 765.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 870/870 [00:02<00:00, 316.96it/s]\n",
      "100%|██████████| 870/870 [00:02<00:00, 388.22it/s]\n",
      "100%|██████████| 864/864 [00:01<00:00, 580.30it/s]\n",
      "100%|██████████| 511/511 [00:01<00:00, 300.86it/s]\n",
      "100%|██████████| 870/870 [00:02<00:00, 350.29it/s]\n",
      "100%|██████████| 842/842 [00:02<00:00, 378.39it/s]\n",
      "100%|██████████| 870/870 [00:02<00:00, 331.68it/s]\n",
      "100%|██████████| 900/900 [00:01<00:00, 665.29it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 683.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjective\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 870/870 [00:02<00:00, 359.52it/s]\n",
      "100%|██████████| 870/870 [00:01<00:00, 454.59it/s]\n",
      "100%|██████████| 864/864 [00:01<00:00, 682.25it/s]\n",
      "100%|██████████| 511/511 [00:01<00:00, 364.52it/s]\n",
      "100%|██████████| 870/870 [00:02<00:00, 401.31it/s]\n",
      "100%|██████████| 842/842 [00:01<00:00, 429.84it/s]\n",
      "100%|██████████| 870/870 [00:02<00:00, 384.27it/s]\n",
      "100%|██████████| 900/900 [00:01<00:00, 802.23it/s]\n",
      "100%|██████████| 770/770 [00:00<00:00, 801.35it/s]\n"
     ]
    }
   ],
   "source": [
    "for pos in [\"noun\", \"verb\", \"adjective\"]:\n",
    "    print(pos)\n",
    "    all_df = pd.read_csv(f\"{output_dir}all_{pos}.csv\")\n",
    "    all_df = all_df.rename(columns={\"count\": \"all_count\",\n",
    "                                    \"ratio\": \"all_ratio\"})\n",
    "\n",
    "    for category in all_category_df[\"category\"].unique():\n",
    "        texts = all_category_df.query(\"category == @category\")[\"text\"].tolist()\n",
    "\n",
    "        result = create_pos_counter_df(texts, pos=pos)\n",
    "        # カテゴリ別リフト値を算出するために使用\n",
    "        count_sum = result[\"count\"].sum()\n",
    "        result[\"ratio\"] = result[\"count\"].apply(lambda x: x / count_sum)\n",
    "        \n",
    "        result = pd.merge(result, all_df, on=pos, how=\"left\")\n",
    "        result[\"lift\"] = result[\"ratio\"] / result[\"all_ratio\"]\n",
    "        \n",
    "        result.to_csv(f\"{output_dir}{category}_{pos}.csv\", \n",
    "                      encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f60a0-7947-4616-8c67-11396101f6e4",
   "metadata": {},
   "source": [
    "# N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9579bc3-66ca-40ec-8523-da5df5520ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(text_list, n):\n",
    "    return [text_list[idx:idx+n] for idx in range(len(text_list))]\n",
    "\n",
    "def create_n_gram_counter_df(texts, n):\n",
    "    \"\"\" 品詞別のカウントDataFrame作成\n",
    "    \n",
    "        args:\n",
    "            texts(list): データフレームの1カラムをリスト化\n",
    "            n(int): n-gramの数\n",
    "        Note:\n",
    "            バグ：前単語と後単語のn-gramが入っている\n",
    "                例　[\"スマート\", \"フォン\", \"関連する\", \"記事\"]の場合\n",
    "                    理想： \"スマート-フォン\", \"関連する-記事\"\n",
    "                    現実: \"スマート-フォン\", \"フォン-関連する\", \"関連する-記事\"\n",
    "    \"\"\"\n",
    "    # Dockerfileで未知語の更新ができなかったため無理やり\n",
    "    # 記号系が後述の[名詞　サ変接続]に引っかかることを回避\n",
    "    mark = \"[!#$%&\\'\\\\\\\\()*+,-./:;<=>?@[\\\\]^_`\"\\\n",
    "           \"\\{|}~「」〔〕“”〈〉『』【】＆＊・（）＄＃＠。、？！｀＋￥％ 　]\"\n",
    "    stop_mark = re.compile(mark)\n",
    "    word = \"(する|いる|れる|なる|ある|できる|られる|せる|おる|てる)\"\n",
    "    stop_word = re.compile(word)\n",
    "    \n",
    "    counter  = {}\n",
    "    for text in tqdm(texts):\n",
    "        \n",
    "        surf_list = []\n",
    "        past_i = 0\n",
    "        past_pos = \"\"\n",
    "        for i, one_pos in enumerate(mc.parse(text).split(\"\\n\")):\n",
    "            if (one_pos == \"EOS\") or (len(one_pos) == 0):\n",
    "                continue\n",
    "\n",
    "            # n-gramに使用する品詞のみのリスト作成\n",
    "            surf, mc_result = one_pos.split(\"\\t\")\n",
    "            #品詞, 品詞細分類1,_,_,_,_,原型, _ \n",
    "            pos0, pos1, _, _, _, _, base, *_ = mc_result.split(\",\")\n",
    "            if (stop_mark.search(surf)) or (stop_word.search(base)):\n",
    "                continue\n",
    "            \n",
    "            if (pos0 in [\"名詞\", \"動詞\", \"形容詞\"]) & \\\n",
    "               (pos1 in [\"一般\", \"固有名詞\", \"自立\",\n",
    "                         \"サ変接続\", \"形容動詞語幹\"]):\n",
    "\n",
    "                if (pos0 == \"名詞\") & (pos1 == \"サ変接続\"):\n",
    "                    if base == \"*\":\n",
    "                        pos = f\"{surf}する\"\n",
    "                    else:\n",
    "                        pos = f\"{base}する\"\n",
    "                else:\n",
    "                    if base == \"*\":\n",
    "                        pos = surf\n",
    "                    else:\n",
    "                        pos = base\n",
    "                \n",
    "                if (i - past_i) == 1:\n",
    "                    if surf_list:\n",
    "                        if surf_list[-1] != past_pos:\n",
    "                            surf_list.append(past_pos)\n",
    "                    surf_list.append(pos)\n",
    "                    \n",
    "                past_i = i\n",
    "                past_pos = pos\n",
    "\n",
    "            else:\n",
    "                past_i = 0\n",
    "                past_pos = \"\"\n",
    "\n",
    "        # n-gramによるカウンター作成\n",
    "        n_gram_list = n_gram(surf_list, n)\n",
    "        for one_n_gram in n_gram_list:\n",
    "            one_n_gram_str = \"-\".join(one_n_gram)\n",
    "\n",
    "            if one_n_gram_str in counter:\n",
    "                counter[one_n_gram_str] += 1\n",
    "            else:\n",
    "                counter[one_n_gram_str] = 1\n",
    "\n",
    "    counter = sorted(counter.items(), \n",
    "                     key=lambda x:x[1], \n",
    "                     reverse=True)\n",
    "    result = pd.DataFrame(counter, columns=[f\"{n}gram\", \"count\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4a130-7808-4280-8a24-f72a1c581633",
   "metadata": {},
   "source": [
    "## 全体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca4afaf5-8977-44d9-a606-60708e24a61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7367/7367 [00:19<00:00, 384.85it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = all_category_df[\"text\"].tolist()\n",
    "n = 2\n",
    "result = create_n_gram_counter_df(texts, n=n)\n",
    "\n",
    "# カテゴリ別リフト値を算出するために使用\n",
    "count_sum = result[\"count\"].sum()\n",
    "result[\"ratio\"] = result[\"count\"].apply(lambda x: x / count_sum)\n",
    "\n",
    "result.to_csv(f\"{output_dir}all_{n}gram.csv\", \n",
    "              encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d28a51-6e70-4a9d-a913-e7710a172b59",
   "metadata": {},
   "source": [
    "## カテゴリ別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8cd3db1-72ee-4d50-93dc-c112075787a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 870/870 [00:02<00:00, 291.11it/s]\n",
      "100%|██████████| 870/870 [00:02<00:00, 347.13it/s]\n",
      "100%|██████████| 864/864 [00:01<00:00, 539.32it/s]\n",
      "100%|██████████| 511/511 [00:01<00:00, 287.28it/s]\n",
      "100%|██████████| 870/870 [00:02<00:00, 335.99it/s]\n",
      "100%|██████████| 842/842 [00:02<00:00, 339.71it/s]\n",
      "100%|██████████| 870/870 [00:02<00:00, 300.41it/s]\n",
      "100%|██████████| 900/900 [00:01<00:00, 652.97it/s]\n",
      "100%|██████████| 770/770 [00:01<00:00, 615.32it/s]\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.read_csv(f\"{output_dir}all_{n}gram.csv\")\n",
    "all_df = all_df.rename(columns={\"count\": \"all_count\",\n",
    "                                \"ratio\": \"all_ratio\"})\n",
    "for category in all_category_df[\"category\"].unique():\n",
    "\n",
    "    texts = all_category_df.query(\"category == @category\")[\"text\"].tolist()\n",
    "    n = 2\n",
    "    result = create_n_gram_counter_df(texts, n=n)\n",
    "\n",
    "    # カテゴリ別リフト値を算出するために使用\n",
    "    count_sum = result[\"count\"].sum()\n",
    "    result[\"ratio\"] = result[\"count\"].apply(lambda x: x / count_sum)\n",
    "    result = pd.merge(result, all_df, on=f\"{n}gram\", how=\"left\")\n",
    "    result[\"lift\"] = result[\"ratio\"] / result[\"all_ratio\"]\n",
    "\n",
    "    result.to_csv(f\"{output_dir}{category}_{n}gram.csv\", \n",
    "                  encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae6491-55ad-4dfb-9a58-ba6dc1b960e5",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b92a562b-393b-444d-9fe9-5726ef5e2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "436bd707-10b4-4822-b867-698a190495cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dddb021c-be76-48d3-a0e9-f5c9c78252f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8c51556-cd66-4fe7-bc17-ec5abf757d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'友人代表のスピーチ、独女はどうこなしている?\\n もうすぐジューン・ブライドと呼ばれる0月。独女の中には自分の式はまだなのに呼ばれてばかり......という「お祝い貧乏」状態の人も多いのではないだろうか? さらに出席回数を重ねていくと、こんなお願いごとをされることも少なくない。\\n\\n 「お願いがあるんだけど......友人代表のスピーチ、やってくれないかな?」\\n\\n さてそんなとき、独女はどう対応したらいいか?\\n\\n 最近だとインターネット等で検索すれば友人代表スピーチ用の例文サイトがたくさん出てくるので、それらを参考にすれば、無難なものは誰でも作成できる。しかし由利さん(00歳)はネットを参考にして作成したものの「これで本当にいいのか不安でした。一人暮らしなので聞かせて感想をいってくれる人もいないし、かといって他の友人にわざわざ聞かせるのもどうかと思うし......」ということで活用したのが、なんとインターネットの悩み相談サイトに。そこに作成したスピーチ文を掲載し「これで大丈夫か添削してください」とメッセージを送ったというのである。\\n\\n 「一晩で0人位の人が添削してくれましたよ。ちなみに自分以外にもそういう人はたくさんいて、その相談サイトには同じように添削をお願いする投稿がいっぱいありました」(由利さん)。ためしに教えてもらったそのサイトをみてみると、確かに「結婚式のスピーチの添削お願いします」という投稿が0000件を超えるくらいあった。めでたい結婚式の影でこんなネットコミュニティがあったとは知らなかった。\\n\\n しかし「事前にお願いされるスピーチなら準備ができるしまだいいですよ。一番嫌なのは何といってもサプライズスピーチ!」と語るのは昨年だけで00万以上お祝いにかかったというお祝い貧乏独女の薫さん(00歳)\\n\\n 「私は基本的に人前で話すのが苦手なんですよ。だからいきなり指名されるとしどろもどろになって何もいえなくなる。そうすると自己嫌悪に陥って終わった後でもまったく楽しめなくなりますね」\\n \\n サプライズスピーチのメリットとしては、準備していない状態なので、フランクな本音をしゃべってもらえるという楽しさがあるようだ。しかしそれも上手に対応できる人ならいいが、苦手な人の場合だと「フランク」ではなく「しどろもどろ」になる危険性大。ちなみにプロの司会者の場合、本当のサプライズではなく式の最中に「のちほどサプライズスピーチとしてご指名させていただきます」という一言があることも多いようだが、薫さん曰く「そんな何分前に言われても無理!」らしい。要は「サプライズを楽しめる」というタイプの人選が大切ということか。\\n\\n 一方「ありきたりじゃつまらないし、ネットで例文を検索している際に『こんな方法もあるのか!』って思って取り入れました」という幸恵さん(00歳)が行ったスピーチは「手紙形式のスピーチ」というもの。\\n\\n 「○○ちゃんへ みたいな感じで新婦の友人にお手紙を書いて読み上げるやり方です。これなら多少フランクな書き方でも大丈夫だし、何より暗記しないで堂々と読み上げることができますよね。読んだものはそのまま友人にあげれば一応記念にもなります」(幸恵さん)\\nなるほど、確かにこれなら読みあげればいいだけなので、人前で話すのが苦手な人でも失敗しないかもしれない。\\n\\n 主役はあくまで新郎新婦ながらも、いざとなると緊張し、内容もあれこれ考えて、こっそりリハーサル......そんな人知れず頑張るスピーチ担当独女たちにも幸あれ(高山惠)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = all_category_df[\"text\"][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d40d2394-1118-4c79-b1ae-1dc476798ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 770/770 [00:01<00:00, 599.95it/s]\n"
     ]
    }
   ],
   "source": [
    "all_sentences = []\n",
    "for text in tqdm(texts):\n",
    "    # Word2Vecを行うための分かち書きリスト作成\n",
    "    sentences = [] # 基本系があれば変換\n",
    "    for one_pos in mc.parse(text).split(\"\\n\"): \n",
    "        if (one_pos == \"EOS\") or (len(one_pos) == 0):\n",
    "            continue\n",
    "\n",
    "        # n-gramに使用する品詞のみのリスト作成\n",
    "        surf, mc_result = one_pos.split(\"\\t\")\n",
    "        #品詞, 品詞細分類1,_,_,_,_,原型, _ \n",
    "        pos0, pos1, _, _, _, _, base, *_ = mc_result.split(\",\")\n",
    "\n",
    "        if base != \"*\":\n",
    "            sentences.append(base)\n",
    "        else:\n",
    "            sentences.append(surf)\n",
    "        \n",
    "    all_sentences.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "676b4915-052c-4839-a352-75b9c2e3c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    all_sentences,\n",
    "    vector_size=300,\n",
    "    window=3,\n",
    "    min_count=3\n",
    "    )\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5387a3e-fcaf-4fc5-9e78-4140147950ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('男性', 0.988882303237915),\n",
       " ('怒り', 0.9864601492881775),\n",
       " ('やりとり', 0.9852823615074158),\n",
       " ('ジャニーズ事務所', 0.9832420945167542),\n",
       " ('毎回', 0.983031153678894),\n",
       " ('同様', 0.9829829931259155),\n",
       " ('距離', 0.982469379901886),\n",
       " ('たち', 0.9822290539741516),\n",
       " ('松嶋', 0.9818447232246399),\n",
       " ('前田', 0.9816654324531555)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 似た意味の単語Top 10\n",
    "# 0から1の値をとり、0が似ていない、1が同じ意味。\n",
    "\n",
    "model.wv.most_similar(\"女性\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e027e8d-71ca-48fd-8dae-da45052d1168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
